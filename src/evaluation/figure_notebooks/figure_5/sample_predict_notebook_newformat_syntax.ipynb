{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4355dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "import tensorflow.keras.backend as kb\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pysam\n",
    "from scipy.special import logsumexp\n",
    "import imageio\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as kb\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class CustomModel(Model):\n",
    "\n",
    "    def __init__(self, num_tasks, tracks_for_each_task, output_profile_len, loss_weights,counts_loss, **kwargs):\n",
    "\n",
    "        # call the base class with inputs and outputs\n",
    "        super(CustomModel, self).__init__(**kwargs)\n",
    "        \n",
    "        # number of tasks\n",
    "        self.num_tasks = num_tasks\n",
    "        \n",
    "        # number of tracks for each task\n",
    "        self.tracks_for_each_task = tracks_for_each_task\n",
    "        \n",
    "        # output profile length\n",
    "        self.output_profile_len = output_profile_len\n",
    "        \n",
    "        # weights for the profile mnll and logcounts losses\n",
    "        self.loss_weights = loss_weights\n",
    "        \n",
    "        # logcounts loss funtion\n",
    "        self.counts_loss = counts_loss\n",
    "        \n",
    "        # object to track overall mean loss per epoch\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "\n",
    "    def _get_loss(self, x, y, sample_weights, training=True):\n",
    "        # boolean mask for sample weights != 0\n",
    "        \n",
    "                \n",
    "        y_pred = self(x, training=training)  # Forward pass\n",
    "        \n",
    "        \n",
    "        def poisson_loss_function(y_log_true, y_log_pred):\n",
    "            # we can use the Possion PMF from TensorFlow as well\n",
    "            # dist = tf.contrib.distributions\n",
    "            # return -tf.reduce_mean(dist.Poisson(y_pred).log_pmf(y_true))\n",
    "\n",
    "            # last term can be avoided since it doesn't depend on y_pred\n",
    "            # however keeping it gives a nice lower bound to zero\n",
    "            \n",
    "            y_true = tf.math.exp(y_log_true)\n",
    "            y_pred = tf.math.exp(y_log_pred)\n",
    "            y_true = tf.cast(y_true,tf.float32)\n",
    "            y_pred = tf.cast(y_pred,tf.float32)\n",
    "            loss = y_pred - y_true*tf.math.log(y_pred+1e-8) + tf.math.lgamma(y_true+1.0)\n",
    "\n",
    "            return loss\n",
    "        \n",
    "        def _poisson_loss_function(_y_log_true,_y_log_pred):\n",
    "            total_poisson_loss = 0\n",
    "            track_count_cuml = 0\n",
    "            num_tasks_count_cuml = 0\n",
    "            for i in range(self.num_tasks):\n",
    "                num_of_tracks = self.tracks_for_each_task[i]\n",
    "                y_log_true = tf.reduce_logsumexp(_y_log_true[:,track_count_cuml:(track_count_cuml+num_of_tracks)],axis=1)\n",
    "                y_log_pred = tf.reduce_logsumexp(_y_log_pred[:,num_tasks_count_cuml:(num_tasks_count_cuml+1)],axis=1)\n",
    "                \n",
    "                loss = poisson_loss_function(y_log_true, y_log_pred)\n",
    "                track_count_cuml += num_of_tracks\n",
    "                num_tasks_count_cuml += 1\n",
    "                total_poisson_loss += loss\n",
    "            return total_poisson_loss\n",
    "    \n",
    "        def mse_loss_function(y_log_true, y_log_pred):\n",
    "            # logcounts mse loss without sample weights\n",
    "            mse_loss = keras.losses.mean_squared_error(\n",
    "                y_log_true, y_log_pred)\n",
    "            return mse_loss\n",
    "        \n",
    "        def _mse_loss_function(_y_log_true,_y_log_pred):\n",
    "            total_mse_loss = 0\n",
    "            track_count_cuml = 0\n",
    "            num_tasks_count_cuml = 0\n",
    "            for i in range(self.num_tasks):\n",
    "                num_of_tracks = self.tracks_for_each_task[i]\n",
    "                y_log_true = tf.reduce_logsumexp(_y_log_true[:,track_count_cuml:(track_count_cuml+num_of_tracks)],axis=1)\n",
    "                y_log_pred = tf.reduce_logsumexp(_y_log_pred[:,num_tasks_count_cuml:(num_tasks_count_cuml+1)],axis=1)\n",
    "                \n",
    "                loss = mse_loss_function(y_log_true, y_log_pred)\n",
    "                track_count_cuml += num_of_tracks\n",
    "                num_tasks_count_cuml += 1\n",
    "                total_mse_loss += loss\n",
    "            return total_mse_loss\n",
    "        \n",
    "        if self.counts_loss == \"MSE\":\n",
    "            total_counts_loss = _mse_loss_function(y['logcounts_predictions'],y_pred[1])\n",
    "        \n",
    "        elif self.counts_loss == \"POISSON\":\n",
    "        \n",
    "            total_counts_loss = _poisson_loss_function(y['logcounts_predictions'],y_pred[1])\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Sorry, unknown loss funtion\")\n",
    "        \n",
    "        boolean_mask = tf.math.greater_equal(sample_weights, 1.0)\n",
    "\n",
    "        # for mnll loss we mask out samples with weight == 0.0\n",
    "        \n",
    "        _y = tf.boolean_mask(y['profile_predictions'], boolean_mask)\n",
    "        _y_pred = tf.boolean_mask(y_pred[0], boolean_mask)\n",
    "\n",
    "        def _zero_constant():\n",
    "            return kb.constant(0)\n",
    "        def multinomial_nll(true_counts, logits):\n",
    "            \"\"\"Compute the multinomial negative log-likelihood\n",
    "            Args:\n",
    "              true_counts: observed count values\n",
    "              logits: predicted logits values\n",
    "            \"\"\"\n",
    "            counts_per_example = tf.reduce_sum(true_counts, axis=-1)\n",
    "            dist = tfp.distributions.Multinomial(total_count=counts_per_example,\n",
    "                                                 logits=logits)\n",
    "            return (-tf.reduce_sum(dist.log_prob(true_counts)) / \n",
    "                    tf.cast(tf.shape(true_counts)[0], dtype=tf.float32))\n",
    "    \n",
    "        def _multinomial_nll(_y,_y_pred):\n",
    "            total_mnll_loss = 0\n",
    "            track_count_cuml = 0\n",
    "            for i in range(self.num_tasks):\n",
    "                num_of_tracks = self.tracks_for_each_task[i]\n",
    "                _y_reshape = tf.reshape(\\\n",
    "                                        _y[:,:,track_count_cuml:(track_count_cuml+num_of_tracks)],\\\n",
    "                                        [-1,(num_of_tracks)*(self.output_profile_len)]\\\n",
    "                                       )\n",
    "                _y_pred_reshape = tf.reshape(\\\n",
    "                                             _y_pred[:,:,track_count_cuml:(track_count_cuml+num_of_tracks)],\\\n",
    "                                             [-1,(num_of_tracks)*(self.output_profile_len)]\\\n",
    "                                            )\n",
    "                \n",
    "                loss = multinomial_nll(_y_reshape, _y_pred_reshape)\n",
    "                track_count_cuml = track_count_cuml+num_of_tracks\n",
    "                total_mnll_loss += loss\n",
    "            return total_mnll_loss\n",
    "                    \n",
    "        total_mnll_loss = tf.cond(tf.equal(tf.size(_y), 0), \n",
    "                  _zero_constant,\n",
    "                  lambda:  _multinomial_nll(_y,_y_pred))\n",
    "        \n",
    "        if self.counts_loss == \"MSE\":\n",
    "            loss =  (self.loss_weights[0] * total_mnll_loss) + \\\n",
    "                (self.loss_weights[1] * total_counts_loss)        \n",
    "        elif self.counts_loss == \"POISSON\":\n",
    "        \n",
    "            loss =  total_mnll_loss + total_counts_loss            \n",
    "        else:\n",
    "            raise Exception(\"Sorry, unknown loss funtion\")\n",
    "\n",
    "        return loss, total_mnll_loss, total_counts_loss\n",
    "            \n",
    "    def train_step(self, data):\n",
    "        x, y, sample_weights = data\n",
    "        print(kb.int_shape(x['sequence']))\n",
    "        print(kb.int_shape(y['profile_predictions']))\n",
    "        print(kb.int_shape(y['logcounts_predictions']))\n",
    "        print(kb.int_shape(sample_weights))        \n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, total_mnll_loss, total_counts_loss = \\\n",
    "                self._get_loss(x, y, sample_weights)\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result(),\n",
    "                \"batch_loss\": loss,\n",
    "                \"profile_predictions_loss\": total_mnll_loss, \n",
    "                \"logcounts_predictions_loss\": total_counts_loss}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y, sample_weights = data\n",
    "        \n",
    "        loss, total_mnll_loss, total_counts_loss = \\\n",
    "            self._get_loss(x, y, sample_weights, training=False)\n",
    "            \n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result(),\n",
    "                \"batch_loss\": loss,\n",
    "                \"profile_predictions_loss\": total_mnll_loss, \n",
    "                \"logcounts_predictions_loss\": total_counts_loss}\n",
    "    \n",
    "def get_model(model_path):\n",
    "    with CustomObjectScope({'MultichannelMultinomialNLL': lambda n='0':n,\n",
    "                            \"kb\": kb,\n",
    "                            \"CustomMeanSquaredError\":lambda n='0':n,\n",
    "                            \"tf\":tf,\n",
    "                           \"CustomModel\":CustomModel}):\n",
    "        model = load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def random_seq(seqlen):\n",
    "    return ''.join(random.choices(\"ACGT\", k=seqlen))\n",
    "\n",
    "\n",
    "\n",
    "def fix_sequence_length(sequence, length):\n",
    "    \"\"\"\n",
    "        Function to check if length of sequence matches specified\n",
    "        length and then return a sequence that's either padded or\n",
    "        truncated to match the given length\n",
    "        Args:\n",
    "            sequence (str): the input sequence\n",
    "            length (int): expected length\n",
    "        Returns:\n",
    "            str: string of length 'length'\n",
    "    \"\"\"\n",
    "\n",
    "    # check if the sequence is smaller than expected length\n",
    "    if len(sequence) < length:\n",
    "        # pad the sequence with 'N's\n",
    "        sequence += 'N' * (length - len(sequence))\n",
    "    # check if the sequence is larger than expected length\n",
    "    elif len(sequence) > length:\n",
    "        # truncate to expected length\n",
    "        sequence = sequence[:length]\n",
    "\n",
    "    return sequence\n",
    "def one_hot_encode(sequences, seq_length):\n",
    "    \"\"\"\n",
    "    \n",
    "       One hot encoding of a list of DNA sequences \n",
    "       \n",
    "       Args:\n",
    "           sequences (list): python list of strings of equal length\n",
    "           seq_length (int): expected length of each sequence in the \n",
    "               list\n",
    "           \n",
    "       Returns:\n",
    "           numpy.ndarray: \n",
    "               3-dimension numpy array with shape \n",
    "               (len(sequences), len(list_item), 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(sequences) == 0:\n",
    "        logging.error(\"'sequences' is empty\")\n",
    "        return None\n",
    "    \n",
    "    # First, let's make sure all sequences are of equal length\n",
    "    sequences = list(map(\n",
    "        fix_sequence_length, sequences, [seq_length] * len(sequences)))\n",
    "\n",
    "    # Step 1. convert sequence list into a single string\n",
    "    _sequences = ''.join(sequences)\n",
    "    \n",
    "    # Step 2. translate the alphabet to a string of digits\n",
    "    transtab = str.maketrans('ACGTNYRMSWK', '01234444444')    \n",
    "    sequences_trans = _sequences.translate(transtab)\n",
    "    \n",
    "    # Step 3. convert to list of ints\n",
    "    int_sequences = list(map(int, sequences_trans))\n",
    "    \n",
    "    # Step 4. one hot encode using int_sequences to index \n",
    "    # into an 'encoder' array\n",
    "    encoder = np.vstack([np.eye(4), np.zeros(4)])\n",
    "    X = encoder[int_sequences]\n",
    "\n",
    "    # Step 5. reshape \n",
    "    return X.reshape(len(sequences), len(sequences[0]), 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7879b7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/anusri/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1059: UserWarning: genomicsdlarchsandlosses.bpnet.archs is not loaded, but a Lambda layer uses it. It may cause errors.\n"
     ]
    }
   ],
   "source": [
    "model_h5=\"/oak/stanford/groups/akundaje/vir/tfatlas/models/production_run_1/fold0/ENCSR124AIG/ENCSR124AIG_split000.h5\"\n",
    "\n",
    "model = get_model(model_path=model_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5a65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "output_seq_len = 1000\n",
    "number_of_strands = 2\n",
    "\n",
    "def softmax(x, temp=1):\n",
    "    norm_x = x - np.mean(x,axis=1, keepdims=True)\n",
    "    return np.exp(temp*norm_x)/np.sum(np.exp(temp*norm_x), axis=1, keepdims=True)\n",
    "\n",
    "output_len=1000\n",
    "#option 2\n",
    "def vectorized_prediction_to_profile(predictions):\n",
    "        logits_arr = predictions[0]\n",
    "        counts_arr = predictions[1]\n",
    "        pred_profile_logits = np.reshape(logits_arr,[-1,1,output_len*2])\n",
    "        probVals_array = np.exp(pred_profile_logits-logsumexp(pred_profile_logits,axis=2).reshape([len(logits_arr),1,1]))\n",
    "        profile_predictions = np.multiply((np.exp(counts_arr)).reshape([len(counts_arr),1,1]),probVals_array)\n",
    "        plus = np.reshape(profile_predictions,[len(counts_arr),output_len,2])[:,:,0]\n",
    "        minus = np.reshape(profile_predictions,[len(counts_arr),output_len,2])[:,:,1]\n",
    "        return(plus,minus)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_footprint_for_motif(seqs, motif, model, inputlen, batch_size):\n",
    "    '''\n",
    "    Returns footprints for a given motif. Motif is inserted in both the actual sequence and reverse complemented version.\n",
    "    seqs input is already assumed to be one-hot encoded. motif is in sequence format.\n",
    "    '''\n",
    "    midpoint=inputlen//2\n",
    "\n",
    "    w_mot_seqs = seqs.copy()\n",
    "    w_mot_seqs[:, midpoint-len(motif)//2:midpoint-len(motif)//2+len(motif)] =dinuc_shuffle_main.dna_to_one_hot([motif])\n",
    "\n",
    "    # midpoint of motif is the midpoint of sequence\n",
    "    \n",
    "    encoded_inserted_sequences = w_mot_seqs\n",
    "\n",
    "    predictions = model.predict([encoded_inserted_sequences,\n",
    "               np.zeros(output_seq_len*number_of_strands*encoded_inserted_sequences.shape[0]).reshape((encoded_inserted_sequences.shape[0],output_seq_len,number_of_strands)),    \n",
    "               np.zeros(encoded_inserted_sequences.shape[0]*number_of_strands).reshape((encoded_inserted_sequences.shape[0],number_of_strands))])\n",
    "\n",
    "    plus,minus = vectorized_prediction_to_profile(predictions)\n",
    "\n",
    "    footprint_for_motif_fwd = plus\n",
    "\n",
    "    # reverse complement the sequence\n",
    "    w_mot_seqs_revc = w_mot_seqs[:, ::-1, ::-1]\n",
    "    \n",
    "    encoded_inserted_sequences = w_mot_seqs_revc\n",
    "\n",
    "    predictions = model.predict([encoded_inserted_sequences,\n",
    "               np.zeros(output_seq_len*number_of_strands*encoded_inserted_sequences.shape[0]).reshape((encoded_inserted_sequences.shape[0],output_seq_len,number_of_strands)),    \n",
    "               np.zeros(encoded_inserted_sequences.shape[0]*number_of_strands).reshape((encoded_inserted_sequences.shape[0],number_of_strands))])\n",
    "\n",
    "    plus,minus = vectorized_prediction_to_profile(predictions)\n",
    "\n",
    "    footprint_for_motif_rev = plus\n",
    "    \n",
    "\n",
    "    # add fwd sequence predictions and reverse sesquence predictions (not we flip the rev predictions)\n",
    "    counts_for_motif = np.sum(footprint_for_motif_fwd,axis=-1)+np.sum(footprint_for_motif_rev,axis=-1)\n",
    "    footprint_for_motif_tot = footprint_for_motif_fwd+footprint_for_motif_rev[:,::-1]\n",
    "    footprint_for_motif =  footprint_for_motif_tot / footprint_for_motif_tot.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    return footprint_for_motif_tot.mean(0), counts_for_motif.mean(0)\n",
    "\n",
    "def get_footprint_for_two_motifs(seqs, motifs, model, inputlen, batch_size, spacing):\n",
    "    '''\n",
    "    Returns footprints for a given motif. Motif is inserted in both the actual sequence and reverse complemented version.\n",
    "    seqs input is already assumed to be one-hot encoded. motif is in sequence format.\n",
    "    '''\n",
    "    midpoint=inputlen//2\n",
    "\n",
    "    spacing_per_motif = spacing // 2\n",
    "    \n",
    "    w_mot_seqs = seqs.copy()\n",
    "    \n",
    "    motif = motifs[0]\n",
    "    start = midpoint-(len(motif)//2)\n",
    "    w_mot_seqs[:, start:start+len(motif)] = dinuc_shuffle_main.dna_to_one_hot([motif])\n",
    "    print(motif,start,start+len(motif))\n",
    "    if spacing > 0:\n",
    "        spacing_per_motif = spacing \n",
    "        motif = motifs[1]\n",
    "        start = start+len(motifs[0])+spacing_per_motif \n",
    "        w_mot_seqs[:, start:start+len(motif)] = dinuc_shuffle_main.dna_to_one_hot([motif])\n",
    "    else:\n",
    "        spacing_per_motif = spacing \n",
    "        motif = motifs[1]\n",
    "        start = start + spacing_per_motif - len(motif)\n",
    "        w_mot_seqs[:, start:start+len(motif)] = dinuc_shuffle_main.dna_to_one_hot([motif])\n",
    "    \n",
    "    encoded_inserted_sequences = w_mot_seqs\n",
    "\n",
    "    predictions = model.predict([encoded_inserted_sequences,\n",
    "               np.zeros(output_seq_len*number_of_strands*encoded_inserted_sequences.shape[0]).reshape((encoded_inserted_sequences.shape[0],output_seq_len,number_of_strands)),    \n",
    "               np.zeros(encoded_inserted_sequences.shape[0]*number_of_strands).reshape((encoded_inserted_sequences.shape[0],number_of_strands))])\n",
    "\n",
    "    plus,minus = vectorized_prediction_to_profile(predictions)\n",
    "\n",
    "    footprint_for_motif_fwd = plus\n",
    "    \n",
    "    # reverse complement the sequence\n",
    "    w_mot_seqs_revc = w_mot_seqs[:, ::-1, ::-1]\n",
    "\n",
    "    encoded_inserted_sequences = w_mot_seqs_revc\n",
    "    predictions = model.predict([encoded_inserted_sequences,\n",
    "               np.zeros(output_seq_len*number_of_strands*encoded_inserted_sequences.shape[0]).reshape((encoded_inserted_sequences.shape[0],output_seq_len,number_of_strands)),    \n",
    "               np.zeros(encoded_inserted_sequences.shape[0]*number_of_strands).reshape((encoded_inserted_sequences.shape[0],number_of_strands))])\n",
    "\n",
    "    plus,minus = vectorized_prediction_to_profile(predictions)\n",
    "\n",
    "    footprint_for_motif_rev = plus\n",
    "    \n",
    "    # add fwd sequence predictions and reverse sesquence predictions (not we flip the rev predictions)\n",
    "    counts_for_motif = np.sum(footprint_for_motif_fwd,axis=-1)+np.sum(footprint_for_motif_rev,axis=-1)\n",
    "    footprint_for_motif_tot = footprint_for_motif_fwd+footprint_for_motif_rev[:,::-1]\n",
    "    footprint_for_motif =  footprint_for_motif_tot / footprint_for_motif_tot.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    return footprint_for_motif_tot.mean(0), counts_for_motif.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbd62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=\"/oak/stanford/groups/akundaje/vir/tfatlas/models/production_run_1/fold0/ENCSR124AIG/ENCSR124AIG_background_regions.bed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca6d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(peaks_df, genome, width, shuffle=False):\n",
    "    \"\"\"\n",
    "    fetches sequence from a given genome.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "\n",
    "    for i, r in peaks_df.iterrows():\n",
    "        sequence = str(genome[r['chr']][(r['start']+r['summit'] - width//2):(r['start'] + r['summit'] + width//2)])\n",
    "        if len(sequence) == width:\n",
    "                vals.append(sequence)\n",
    "\n",
    "    return dinuc_shuffle_main.dna_to_one_hot(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78374282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish as dd\n",
    "import os\n",
    "import pyfaidx\n",
    "import random\n",
    "import pickle as pkl\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import json\n",
    "import one_hot as dinuc_shuffle_main\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42 \n",
    "\n",
    "genome = \"/mnt/lab_data2/anusri/chrombpnet/reference/hg38.genome.fa\"\n",
    "\n",
    "NARROWPEAK_SCHEMA = [\"chr\", \"start\", \"end\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"summit\"]\n",
    "inputlen = 2114\n",
    "regions_df = pd.read_csv(regions, sep='\\t', names=NARROWPEAK_SCHEMA)\n",
    "chroms_to_keep = [\"chr1\"]\n",
    "regions_subsample = regions_df[(regions_df[\"chr\"].isin(chroms_to_keep))].sample(1000, random_state=0)\n",
    "genome_fasta = pyfaidx.Fasta(genome)\n",
    "regions_seqs = get_seq(regions_subsample, genome_fasta, inputlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b5d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n"
     ]
    }
   ],
   "source": [
    "motifs = [\"AGGAATGT\",\"TTGACTCA\"]\n",
    "batch_size=250\n",
    "output_len=1000\n",
    "data_in_spacings = []\n",
    "for spacing in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40]:\n",
    "    puu_runx_footprint = get_footprint_for_two_motifs(regions_seqs, motifs, model, inputlen, batch_size, spacing=-1*spacing)\n",
    "    data_in_spacings.append(puu_runx_footprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edaf38d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n",
      "AGGAATGT 1053 1061\n"
     ]
    }
   ],
   "source": [
    "motifs = [\"AGGAATGT\",\"TTGACTCA\"]\n",
    "\n",
    "data_in_spacings_rev = []\n",
    "for spacing in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40]:\n",
    "    puu_runx_footprint = get_footprint_for_two_motifs(regions_seqs, motifs, model, inputlen, batch_size, spacing=spacing)\n",
    "    data_in_spacings_rev.append(puu_runx_footprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bf3c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa5c05af810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_counts = [x[1] for x in data_in_spacings]\n",
    "all_counts_rev = [x[1] for x in data_in_spacings_rev]\n",
    "\n",
    "\n",
    "plt.scatter([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40]+[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-20,-40],all_counts_rev+all_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123efc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\", {'axes.grid' : False})\n",
    "\n",
    "plt.scatter([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40]+[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-20,-40],all_counts_rev[0:]+all_counts[0:], linewidths=0.5, edgecolors=None,s=5)\n",
    "plt.plot([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40]+[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-20,-40],all_counts_rev[0:]+all_counts[0:], alpha=0.5 )\n",
    "\n",
    "# Dataset\n",
    "x = np.array([-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-20,-40][::-1]+[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,40])\n",
    "y = np.array(all_counts[::-1]+all_counts_rev)\n",
    "\n",
    "X_Y_Spline = make_interp_spline(x, y)\n",
    " \n",
    "# Returns evenly spaced numbers\n",
    "# over a specified interval.\n",
    "X_ = np.linspace(x.min(), x.max(), 500)\n",
    "#Y_ = X_Y_Spline(X_)\n",
    "\n",
    "plt.axvline(-6, color=\"orange\", linestyle=\"-\")  #vertical line\n",
    "#plt.plot(X_,Y_)\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"AP1 spacing from TEAD\")\n",
    "\n",
    "plt.savefig(\"subfigs/ap1_tead_syntax_chip.pdf\", transparent=True, dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b2af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce149e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
